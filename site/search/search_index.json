{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"jax_mppi","text":"<p>jax_mppi is a functional, JIT-compilable port of the pytorch_mppi library to JAX. It implements Model Predictive Path Integral (MPPI) control with a focus on performance and composability.</p>"},{"location":"#design-philosophy","title":"Design Philosophy","text":"<p>This library embraces JAX's functional paradigm:</p> <ul> <li>Pure Functions: Core logic is implemented as pure functions <code>command(state, mppi_state) -&gt; (action, mppi_state)</code>.</li> <li>Dataclass State: State is held in <code>jax.tree_util.register_dataclass</code> containers, allowing easy integration with <code>jit</code>, <code>vmap</code>, and <code>grad</code>.</li> <li>No Side Effects: Unlike the PyTorch version, there is no mutable <code>self</code>. State transitions are explicit.</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Core MPPI: Robust implementation of the standard MPPI algorithm.</li> <li>Smooth MPPI (SMPPI): Maintains action sequences and smoothness costs for better trajectory generation.</li> <li>Kernel MPPI (KMPPI): Uses kernel interpolation for control points, reducing the parameter space.</li> <li>JAX Integration:<ul> <li><code>jax.vmap</code> for efficient batch processing.</li> <li><code>jax.lax.scan</code> for fast horizon loops.</li> <li>Fully compatible with JIT compilation for high-performance control loops.</li> </ul> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/yourusername/jax_mppi.git\ncd jax_mppi\n\n# Install dependencies\npip install -e .\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom jax_mppi import mppi\n\n# Define dynamics and cost functions\ndef dynamics(state, action):\n    # Your dynamics model here\n    return state + action\n\ndef running_cost(state, action):\n    # Your cost function here\n    return jnp.sum(state**2) + jnp.sum(action**2)\n\n# Create configuration and initial state\nconfig, mppi_state = mppi.create(\n    nx=4, nu=2,\n    noise_sigma=jnp.eye(2) * 0.1,\n    horizon=20,\n    lambda_=1.0\n)\n\n# Control loop\nkey = jax.random.PRNGKey(0)\ncurrent_obs = jnp.zeros(4)\n\n# JIT compile the command function for performance\njitted_command = jax.jit(mppi.command, static_argnames=['dynamics', 'running_cost'])\n\nfor _ in range(100):\n    key, subkey = jax.random.split(key)\n    action, mppi_state = jitted_command(\n        config,\n        mppi_state,\n        current_obs,\n        dynamics=dynamics,\n        running_cost=running_cost\n    )\n    # Apply action to environment...\n</code></pre>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>jax_mppi/\n\u251c\u2500\u2500 src/jax_mppi/\n\u2502   \u251c\u2500\u2500 mppi.py              # Core MPPI implementation\n\u2502   \u251c\u2500\u2500 smppi.py             # Smooth MPPI variant\n\u2502   \u251c\u2500\u2500 kmppi.py             # Kernel MPPI variant\n\u2502   \u2514\u2500\u2500 types.py             # Type definitions\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 pendulum.py          # Pendulum environment example\n\u2502   \u2514\u2500\u2500 smooth_comparison.py # Comparison of MPPI variants\n\u2514\u2500\u2500 tests/                   # Unit and integration tests\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<p>The development is structured in phases:</p> <ol> <li>Core MPPI: Basic implementation with JAX parity.</li> <li>Integration: Pendulum example and verification.</li> <li>Smooth MPPI: Implementation of smoothness constraints.</li> <li>Kernel MPPI: Kernel-based control parameterization.</li> <li>Comparisons: Benchmarking and visual comparisons.</li> <li>Autotuning: Parameter optimization using CMA-ES.</li> </ol>"},{"location":"#credits","title":"Credits","text":"<p>This project is a direct port of pytorch_mppi. We aim to maintain parity with the original implementation while leveraging JAX's unique features for performance and flexibility.</p>"},{"location":"api/kmppi/","title":"KMPPI","text":"<p>Kernel MPPI (KMPPI) implementation in JAX.</p> <p>KMPPI uses kernel interpolation to smooth control trajectories by working with a reduced set of control points (theta) rather than the full trajectory. This allows smoother actions with fewer parameters to optimize.</p> <p>Reference: Based on pytorch_mppi KMPPI implementation</p>"},{"location":"api/kmppi/#jax_mppi.kmppi.KMPPIConfig","title":"<code>KMPPIConfig</code>  <code>dataclass</code>","text":"<p>Configuration for Kernel MPPI.</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>@dataclass(frozen=True)\nclass KMPPIConfig:\n    \"\"\"Configuration for Kernel MPPI.\"\"\"\n\n    # Base MPPI parameters\n    num_samples: int  # K\n    horizon: int  # T\n    nx: int\n    nu: int\n    lambda_: float\n    u_scale: float\n    u_per_command: int\n    step_dependent_dynamics: bool\n    rollout_samples: int  # M\n    rollout_var_cost: float\n    rollout_var_discount: float\n    sample_null_action: bool\n    noise_abs_cost: bool\n\n    # KMPPI-specific parameters\n    num_support_pts: int  # Number of control points for interpolation\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.KMPPIState","title":"<code>KMPPIState</code>  <code>dataclass</code>","text":"<p>State for Kernel MPPI.</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>@register_pytree_node_class\n@dataclass\nclass KMPPIState:\n    \"\"\"State for Kernel MPPI.\"\"\"\n\n    # Base parameters\n    U: jax.Array  # (T, nu) full trajectory (interpolated from theta)\n    u_init: jax.Array  # (nu,) default action for shift\n    noise_mu: jax.Array  # (nu,)\n    noise_sigma: jax.Array  # (nu, nu)\n    noise_sigma_inv: jax.Array\n    u_min: Optional[jax.Array]\n    u_max: Optional[jax.Array]\n    key: jax.Array  # PRNG key\n\n    # KMPPI-specific state\n    theta: jax.Array  # (num_support_pts, nu) control points\n    Tk: jax.Array  # (num_support_pts,) control point times\n    Hs: jax.Array  # (T,) full trajectory times\n\n    def tree_flatten(self):\n        return (\n            (\n                self.U,\n                self.u_init,\n                self.noise_mu,\n                self.noise_sigma,\n                self.noise_sigma_inv,\n                self.u_min,\n                self.u_max,\n                self.key,\n                self.theta,\n                self.Tk,\n                self.Hs,\n            ),\n            None,\n        )\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children):\n        return cls(*children)\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.RBFKernel","title":"<code>RBFKernel</code>","text":"<p>Radial Basis Function kernel for time-domain interpolation.</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>class RBFKernel:\n    \"\"\"Radial Basis Function kernel for time-domain interpolation.\"\"\"\n\n    def __init__(self, sigma: float = 1.0):\n        \"\"\"Initialize RBF kernel.\n\n        Args:\n            sigma: Bandwidth parameter (controls kernel width)\n        \"\"\"\n        self.sigma = sigma\n\n    def __call__(self, t: jax.Array, tk: jax.Array) -&gt; jax.Array:\n        \"\"\"Evaluate RBF kernel: k(t, tk) = exp(-||t - tk||^2 / (2*sigma^2))\n\n        Args:\n            t: Query times, shape (T,) or (T, 1)\n            tk: Control point times, shape (num_support_pts,) or (num_support_pts, 1)\n\n        Returns:\n            K: kernel matrix, shape (T, num_support_pts)\n        \"\"\"\n        # Ensure proper shapes for broadcasting\n        if t.ndim == 1:\n            t = t[:, None]  # (T, 1)\n        if tk.ndim == 1:\n            tk = tk[None, :]  # (1, num_support_pts)\n\n        # Squared Euclidean distance in 1D time space\n        # t[:, None] - tk creates (T, num_support_pts) difference matrix\n        d = (t - tk) ** 2\n\n        # RBF formula\n        k = jnp.exp(-d / (2 * self.sigma**2 + 1e-8))\n\n        return k\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.RBFKernel.__call__","title":"<code>__call__(t, tk)</code>","text":"<p>Evaluate RBF kernel: k(t, tk) = exp(-||t - tk||^2 / (2*sigma^2))</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Array</code> <p>Query times, shape (T,) or (T, 1)</p> required <code>tk</code> <code>Array</code> <p>Control point times, shape (num_support_pts,) or (num_support_pts, 1)</p> required <p>Returns:</p> Name Type Description <code>K</code> <code>Array</code> <p>kernel matrix, shape (T, num_support_pts)</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def __call__(self, t: jax.Array, tk: jax.Array) -&gt; jax.Array:\n    \"\"\"Evaluate RBF kernel: k(t, tk) = exp(-||t - tk||^2 / (2*sigma^2))\n\n    Args:\n        t: Query times, shape (T,) or (T, 1)\n        tk: Control point times, shape (num_support_pts,) or (num_support_pts, 1)\n\n    Returns:\n        K: kernel matrix, shape (T, num_support_pts)\n    \"\"\"\n    # Ensure proper shapes for broadcasting\n    if t.ndim == 1:\n        t = t[:, None]  # (T, 1)\n    if tk.ndim == 1:\n        tk = tk[None, :]  # (1, num_support_pts)\n\n    # Squared Euclidean distance in 1D time space\n    # t[:, None] - tk creates (T, num_support_pts) difference matrix\n    d = (t - tk) ** 2\n\n    # RBF formula\n    k = jnp.exp(-d / (2 * self.sigma**2 + 1e-8))\n\n    return k\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.RBFKernel.__init__","title":"<code>__init__(sigma=1.0)</code>","text":"<p>Initialize RBF kernel.</p> <p>Parameters:</p> Name Type Description Default <code>sigma</code> <code>float</code> <p>Bandwidth parameter (controls kernel width)</p> <code>1.0</code> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def __init__(self, sigma: float = 1.0):\n    \"\"\"Initialize RBF kernel.\n\n    Args:\n        sigma: Bandwidth parameter (controls kernel width)\n    \"\"\"\n    self.sigma = sigma\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.TimeKernel","title":"<code>TimeKernel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for time-domain kernels used in trajectory interpolation.</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>class TimeKernel(Protocol):\n    \"\"\"Protocol for time-domain kernels used in trajectory interpolation.\"\"\"\n\n    def __call__(self, t: jax.Array, tk: jax.Array) -&gt; jax.Array:\n        \"\"\"Evaluate kernel between time points.\n\n        Args:\n            t: Query time points, shape (T,) or (T, 1)\n            tk: Control point times, shape (num_support_pts,) or (num_support_pts, 1)\n\n        Returns:\n            K: Kernel matrix, shape (T, num_support_pts)\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.TimeKernel.__call__","title":"<code>__call__(t, tk)</code>","text":"<p>Evaluate kernel between time points.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Array</code> <p>Query time points, shape (T,) or (T, 1)</p> required <code>tk</code> <code>Array</code> <p>Control point times, shape (num_support_pts,) or (num_support_pts, 1)</p> required <p>Returns:</p> Name Type Description <code>K</code> <code>Array</code> <p>Kernel matrix, shape (T, num_support_pts)</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def __call__(self, t: jax.Array, tk: jax.Array) -&gt; jax.Array:\n    \"\"\"Evaluate kernel between time points.\n\n    Args:\n        t: Query time points, shape (T,) or (T, 1)\n        tk: Control point times, shape (num_support_pts,) or (num_support_pts, 1)\n\n    Returns:\n        K: Kernel matrix, shape (T, num_support_pts)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.command","title":"<code>command(config, kmppi_state, current_obs, dynamics, running_cost, kernel_fn, terminal_cost=None, shift=True)</code>","text":"<p>Compute optimal action using Kernel MPPI.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>KMPPIConfig</code> <p>KMPPI configuration</p> required <code>kmppi_state</code> <code>KMPPIState</code> <p>Current KMPPI state</p> required <code>current_obs</code> <code>Array</code> <p>(nx,) current observation/state</p> required <code>dynamics</code> <code>DynamicsFn</code> <p>Dynamics function</p> required <code>running_cost</code> <code>RunningCostFn</code> <p>Running cost function</p> required <code>kernel_fn</code> <code>TimeKernel</code> <p>Kernel function for interpolation</p> required <code>terminal_cost</code> <code>Optional[TerminalCostFn]</code> <p>Optional terminal cost function</p> <code>None</code> <code>shift</code> <code>bool</code> <p>Whether to shift nominal trajectory after computing action</p> <code>True</code> <p>Returns:</p> Name Type Description <code>action</code> <code>Array</code> <p>(u_per_command * nu,) or (nu,) optimal action</p> <code>new_state</code> <code>KMPPIState</code> <p>Updated KMPPI state</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def command(\n    config: KMPPIConfig,\n    kmppi_state: KMPPIState,\n    current_obs: jax.Array,\n    dynamics: DynamicsFn,\n    running_cost: RunningCostFn,\n    kernel_fn: TimeKernel,\n    terminal_cost: Optional[TerminalCostFn] = None,\n    shift: bool = True,\n) -&gt; Tuple[jax.Array, KMPPIState]:\n    \"\"\"Compute optimal action using Kernel MPPI.\n\n    Args:\n        config: KMPPI configuration\n        kmppi_state: Current KMPPI state\n        current_obs: (nx,) current observation/state\n        dynamics: Dynamics function\n        running_cost: Running cost function\n        kernel_fn: Kernel function for interpolation\n        terminal_cost: Optional terminal cost function\n        shift: Whether to shift nominal trajectory after computing action\n\n    Returns:\n        action: (u_per_command * nu,) or (nu,) optimal action\n        new_state: Updated KMPPI state\n    \"\"\"\n    # Sample noise in control point space\n    noise_theta, new_key = _sample_noise(\n        kmppi_state.key,\n        config.num_samples,\n        config.num_support_pts,\n        kmppi_state.noise_mu,\n        kmppi_state.noise_sigma,\n        config.sample_null_action,\n    )\n\n    # Perturb control points\n    perturbed_theta = (\n        kmppi_state.theta[None, :, :] + noise_theta\n    )  # (K, num_support_pts, nu)\n    perturbed_theta = _bound_action(\n        perturbed_theta, kmppi_state.u_min, kmppi_state.u_max\n    )\n\n    # Effective noise after bounding\n    effective_noise_theta = perturbed_theta - kmppi_state.theta[None, :, :]\n\n    # Interpolate perturbed control points to full trajectories\n    def interpolate_single(theta_single):\n        U_interp, _ = _kernel_interpolate(\n            kmppi_state.Hs, kmppi_state.Tk, theta_single, kernel_fn\n        )\n        return U_interp\n\n    perturbed_actions = jax.vmap(interpolate_single)(perturbed_theta)  # (K, T, nu)\n    perturbed_actions = _bound_action(\n        perturbed_actions, kmppi_state.u_min, kmppi_state.u_max\n    )\n\n    # Compute rollout costs\n    rollout_costs = _compute_rollout_costs(\n        config,\n        current_obs,\n        perturbed_actions,\n        dynamics,\n        running_cost,\n        terminal_cost,\n    )\n\n    # Compute noise cost (in control point space)\n    noise_costs = _compute_noise_cost(\n        effective_noise_theta,\n        kmppi_state.noise_sigma_inv,\n        config.noise_abs_cost,\n    )\n\n    # Total cost\n    total_costs = rollout_costs + noise_costs\n\n    # Compute importance weights\n    weights = _compute_weights(total_costs, config.lambda_)\n\n    # Update control points (optimization in control point space)\n    delta_theta = jnp.sum(weights[:, None, None] * effective_noise_theta, axis=0)\n    new_theta = kmppi_state.theta + delta_theta\n\n    # Interpolate updated control points to get full trajectory\n    new_U, _ = _kernel_interpolate(kmppi_state.Hs, kmppi_state.Tk, new_theta, kernel_fn)\n\n    # Update state\n    new_state = replace(\n        kmppi_state,\n        U=new_U,\n        theta=new_theta,\n        key=new_key,\n    )\n\n    # Shift nominal trajectory if requested\n    if shift:\n        shifted_theta = _shift_control_points(\n            new_state.theta,\n            new_state.Tk,\n            new_state.u_init,\n            config.u_per_command,\n            kernel_fn,\n        )\n        # Also shift U (via interpolation)\n        shifted_U, _ = _kernel_interpolate(\n            new_state.Hs, new_state.Tk, shifted_theta, kernel_fn\n        )\n        new_state = replace(new_state, U=shifted_U, theta=shifted_theta)\n\n    # Extract action to return\n    if config.u_per_command == 1:\n        action = new_state.U[0] * config.u_scale\n    else:\n        action = new_state.U[: config.u_per_command].reshape(-1) * config.u_scale\n\n    return action, new_state\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.create","title":"<code>create(nx, nu, noise_sigma, num_samples=100, horizon=15, lambda_=1.0, noise_mu=None, u_min=None, u_max=None, u_init=None, U_init=None, num_support_pts=None, kernel=None, u_scale=1.0, u_per_command=1, step_dependent_dynamics=False, rollout_samples=1, rollout_var_cost=0.0, rollout_var_discount=0.95, sample_null_action=False, noise_abs_cost=False, key=None)</code>","text":"<p>Create KMPPI configuration, state, and kernel.</p> <p>Parameters:</p> Name Type Description Default <code>nx</code> <code>int</code> <p>State dimension</p> required <code>nu</code> <code>int</code> <p>Action dimension</p> required <code>noise_sigma</code> <code>Array</code> <p>(nu, nu) noise covariance matrix</p> required <code>num_samples</code> <code>int</code> <p>Number of MPPI samples (K)</p> <code>100</code> <code>horizon</code> <code>int</code> <p>Planning horizon (T)</p> <code>15</code> <code>lambda_</code> <code>float</code> <p>Temperature parameter for importance weighting</p> <code>1.0</code> <code>noise_mu</code> <code>Optional[Array]</code> <p>(nu,) noise mean (default: zeros)</p> <code>None</code> <code>u_min</code> <code>Optional[Array]</code> <p>(nu,) lower bounds on actions</p> <code>None</code> <code>u_max</code> <code>Optional[Array]</code> <p>(nu,) upper bounds on actions</p> <code>None</code> <code>u_init</code> <code>Optional[Array]</code> <p>(nu,) default action for shift (default: zeros)</p> <code>None</code> <code>U_init</code> <code>Optional[Array]</code> <p>(T, nu) initial trajectory (default: zeros)</p> <code>None</code> <code>num_support_pts</code> <code>Optional[int]</code> <p>Number of control points (default: horizon // 2)</p> <code>None</code> <code>kernel</code> <code>Optional[TimeKernel]</code> <p>TimeKernel instance (default: RBFKernel(sigma=1.0))</p> <code>None</code> <code>u_scale</code> <code>float</code> <p>Scale factor for control</p> <code>1.0</code> <code>u_per_command</code> <code>int</code> <p>Number of control steps per command</p> <code>1</code> <code>step_dependent_dynamics</code> <code>bool</code> <p>Whether dynamics depend on timestep</p> <code>False</code> <code>rollout_samples</code> <code>int</code> <p>Number of rollout samples for stochastic dynamics</p> <code>1</code> <code>rollout_var_cost</code> <code>float</code> <p>Variance cost weight</p> <code>0.0</code> <code>rollout_var_discount</code> <code>float</code> <p>Discount factor for variance cost</p> <code>0.95</code> <code>sample_null_action</code> <code>bool</code> <p>Whether to include null action in samples</p> <code>False</code> <code>noise_abs_cost</code> <code>bool</code> <p>Use absolute value cost for noise</p> <code>False</code> <code>key</code> <code>Optional[Array]</code> <p>PRNG key (default: create new)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>config</code> <code>KMPPIConfig</code> <p>KMPPI configuration</p> <code>state</code> <code>KMPPIState</code> <p>KMPPI initial state</p> <code>kernel_fn</code> <code>TimeKernel</code> <p>Kernel function instance</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def create(\n    nx: int,\n    nu: int,\n    noise_sigma: jax.Array,\n    num_samples: int = 100,\n    horizon: int = 15,\n    lambda_: float = 1.0,\n    noise_mu: Optional[jax.Array] = None,\n    u_min: Optional[jax.Array] = None,\n    u_max: Optional[jax.Array] = None,\n    u_init: Optional[jax.Array] = None,\n    U_init: Optional[jax.Array] = None,\n    num_support_pts: Optional[int] = None,\n    kernel: Optional[TimeKernel] = None,\n    u_scale: float = 1.0,\n    u_per_command: int = 1,\n    step_dependent_dynamics: bool = False,\n    rollout_samples: int = 1,\n    rollout_var_cost: float = 0.0,\n    rollout_var_discount: float = 0.95,\n    sample_null_action: bool = False,\n    noise_abs_cost: bool = False,\n    key: Optional[jax.Array] = None,\n) -&gt; Tuple[KMPPIConfig, KMPPIState, TimeKernel]:\n    \"\"\"Create KMPPI configuration, state, and kernel.\n\n    Args:\n        nx: State dimension\n        nu: Action dimension\n        noise_sigma: (nu, nu) noise covariance matrix\n        num_samples: Number of MPPI samples (K)\n        horizon: Planning horizon (T)\n        lambda_: Temperature parameter for importance weighting\n        noise_mu: (nu,) noise mean (default: zeros)\n        u_min: (nu,) lower bounds on actions\n        u_max: (nu,) upper bounds on actions\n        u_init: (nu,) default action for shift (default: zeros)\n        U_init: (T, nu) initial trajectory (default: zeros)\n        num_support_pts: Number of control points (default: horizon // 2)\n        kernel: TimeKernel instance (default: RBFKernel(sigma=1.0))\n        u_scale: Scale factor for control\n        u_per_command: Number of control steps per command\n        step_dependent_dynamics: Whether dynamics depend on timestep\n        rollout_samples: Number of rollout samples for stochastic dynamics\n        rollout_var_cost: Variance cost weight\n        rollout_var_discount: Discount factor for variance cost\n        sample_null_action: Whether to include null action in samples\n        noise_abs_cost: Use absolute value cost for noise\n        key: PRNG key (default: create new)\n\n    Returns:\n        config: KMPPI configuration\n        state: KMPPI initial state\n        kernel_fn: Kernel function instance\n    \"\"\"\n    # Initialize defaults\n    if noise_mu is None:\n        noise_mu = jnp.zeros(nu)\n    if u_init is None:\n        u_init = jnp.zeros(nu)\n    if key is None:\n        key = jax.random.PRNGKey(0)\n    if num_support_pts is None:\n        num_support_pts = max(horizon // 2, 2)  # At least 2 support points\n    if kernel is None:\n        kernel = RBFKernel(sigma=1.0)\n\n    # Scale bounds\n    u_min_scaled = _scaled_bounds(u_min, u_scale)\n    u_max_scaled = _scaled_bounds(u_max, u_scale)\n\n    # Initialize control points (theta) and time grids\n    if U_init is None:\n        theta = jnp.zeros((num_support_pts, nu))\n    else:\n        # Sample initial control points from U_init\n        indices = jnp.linspace(0, horizon - 1, num_support_pts, dtype=jnp.int32)\n        theta = U_init[indices]\n\n    # Time grids\n    Tk = jnp.linspace(0, horizon - 1, num_support_pts)  # Control point times\n    Hs = jnp.linspace(0, horizon - 1, horizon)  # Full trajectory times\n\n    # Interpolate theta to get full trajectory U\n    U, _ = _kernel_interpolate(Hs, Tk, theta, kernel)\n\n    # Compute noise covariance inverse\n    noise_sigma_inv = jnp.linalg.inv(noise_sigma)\n\n    # Create config\n    config = KMPPIConfig(\n        num_samples=num_samples,\n        horizon=horizon,\n        nx=nx,\n        nu=nu,\n        lambda_=lambda_,\n        u_scale=u_scale,\n        u_per_command=u_per_command,\n        step_dependent_dynamics=step_dependent_dynamics,\n        rollout_samples=rollout_samples,\n        rollout_var_cost=rollout_var_cost,\n        rollout_var_discount=rollout_var_discount,\n        sample_null_action=sample_null_action,\n        noise_abs_cost=noise_abs_cost,\n        num_support_pts=num_support_pts,\n    )\n\n    # Create state\n    state = KMPPIState(\n        U=U,\n        u_init=u_init,\n        noise_mu=noise_mu,\n        noise_sigma=noise_sigma,\n        noise_sigma_inv=noise_sigma_inv,\n        u_min=u_min_scaled,\n        u_max=u_max_scaled,\n        key=key,\n        theta=theta,\n        Tk=Tk,\n        Hs=Hs,\n    )\n\n    return config, state, kernel\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.get_rollouts","title":"<code>get_rollouts(config, kmppi_state, current_obs, dynamics, num_rollouts=1)</code>","text":"<p>Generate rollout trajectories using current control sequence.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>KMPPIConfig</code> <p>KMPPI configuration</p> required <code>kmppi_state</code> <code>KMPPIState</code> <p>Current KMPPI state</p> required <code>current_obs</code> <code>Array</code> <p>(nx,) or (batch, nx) current state</p> required <code>dynamics</code> <code>DynamicsFn</code> <p>Dynamics function</p> required <code>num_rollouts</code> <code>int</code> <p>Number of rollout samples</p> <code>1</code> <p>Returns:</p> Name Type Description <code>rollouts</code> <code>Array</code> <p>(num_rollouts, horizon+1, nx) state trajectories</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def get_rollouts(\n    config: KMPPIConfig,\n    kmppi_state: KMPPIState,\n    current_obs: jax.Array,\n    dynamics: DynamicsFn,\n    num_rollouts: int = 1,\n) -&gt; jax.Array:\n    \"\"\"Generate rollout trajectories using current control sequence.\n\n    Args:\n        config: KMPPI configuration\n        kmppi_state: Current KMPPI state\n        current_obs: (nx,) or (batch, nx) current state\n        dynamics: Dynamics function\n        num_rollouts: Number of rollout samples\n\n    Returns:\n        rollouts: (num_rollouts, horizon+1, nx) state trajectories\n    \"\"\"\n\n    def single_rollout(carry, _):\n        state = carry\n\n        def step_fn(s, inputs):\n            t, action = inputs\n            next_s = _call_dynamics(\n                dynamics, s, action, t, config.step_dependent_dynamics\n            )\n            next_s_trimmed = _state_for_cost(next_s, config.nx)\n            return next_s, next_s_trimmed\n\n        ts = jnp.arange(config.horizon)\n        _, trajectory = jax.lax.scan(step_fn, state, (ts, kmppi_state.U))\n\n        # Prepend initial state\n        initial_state = _state_for_cost(state, config.nx)\n        full_trajectory = jnp.concatenate([initial_state[None, :], trajectory], axis=0)\n\n        return state, full_trajectory\n\n    # Handle batched or single state\n    if current_obs.ndim == 1:\n        obs_batch = current_obs[None, :]\n    else:\n        obs_batch = current_obs\n\n    # Generate multiple rollouts\n    _, rollouts = jax.lax.scan(single_rollout, obs_batch[0], jnp.arange(num_rollouts))\n\n    return rollouts\n</code></pre>"},{"location":"api/kmppi/#jax_mppi.kmppi.reset","title":"<code>reset(config, kmppi_state, kernel_fn, key)</code>","text":"<p>Reset KMPPI state with new random key.</p> Source code in <code>src/jax_mppi/kmppi.py</code> <pre><code>def reset(\n    config: KMPPIConfig, kmppi_state: KMPPIState, kernel_fn: TimeKernel, key: jax.Array\n) -&gt; KMPPIState:\n    \"\"\"Reset KMPPI state with new random key.\"\"\"\n    # Reset control points to zeros\n    theta_reset = jnp.zeros_like(kmppi_state.theta)\n\n    # Interpolate to get U\n    U_reset, _ = _kernel_interpolate(\n        kmppi_state.Hs, kmppi_state.Tk, theta_reset, kernel_fn\n    )\n\n    return replace(\n        kmppi_state,\n        U=U_reset,\n        theta=theta_reset,\n        key=key,\n    )\n</code></pre>"},{"location":"api/mppi/","title":"MPPI","text":""},{"location":"api/mppi/#jax_mppi.mppi.command","title":"<code>command(config, mppi_state, current_obs, dynamics, running_cost, terminal_cost=None, shift=True)</code>","text":"<p>Compute optimal action and return updated state.</p> Source code in <code>src/jax_mppi/mppi.py</code> <pre><code>def command(\n    config: MPPIConfig,\n    mppi_state: MPPIState,\n    current_obs: jax.Array,\n    dynamics: DynamicsFn,\n    running_cost: RunningCostFn,\n    terminal_cost: Optional[TerminalCostFn] = None,\n    shift: bool = True,\n) -&gt; Tuple[jax.Array, MPPIState]:\n    \"\"\"Compute optimal action and return updated state.\"\"\"\n    noise, key = _sample_noise(\n        mppi_state.key,\n        config.num_samples,\n        config.horizon,\n        mppi_state.noise_mu,\n        mppi_state.noise_sigma,\n        config.sample_null_action,\n    )\n\n    perturbed_actions = mppi_state.U[None, :, :] + noise\n    scaled_actions = perturbed_actions * config.u_scale\n    scaled_actions = _bound_action(scaled_actions, mppi_state.u_min, mppi_state.u_max)\n\n    rollout_costs = _compute_rollout_costs(\n        config,\n        current_obs,\n        scaled_actions,\n        dynamics,\n        running_cost,\n        terminal_cost,\n    )\n    noise_costs = _compute_noise_cost(noise, mppi_state.noise_sigma_inv, config.noise_abs_cost)\n    total_costs = rollout_costs + noise_costs\n\n    weights = _compute_weights(total_costs, config.lambda_)\n    delta_U = jnp.tensordot(weights, noise, axes=1)\n    U_new = mppi_state.U + delta_U\n\n    u_min_scaled, u_max_scaled = _scaled_bounds(mppi_state.u_min, mppi_state.u_max, config.u_scale)\n    U_new = _bound_action(U_new, u_min_scaled, u_max_scaled)\n\n    action_seq = U_new[:config.u_per_command]\n    scaled_action_seq = _bound_action(action_seq * config.u_scale, mppi_state.u_min, mppi_state.u_max)\n    action = scaled_action_seq[0] if config.u_per_command == 1 else scaled_action_seq\n\n    new_state = replace(mppi_state, U=U_new, key=key)\n    if shift:\n        new_state = _shift_nominal(new_state, config.u_per_command)\n\n    return action, new_state\n</code></pre>"},{"location":"api/mppi/#jax_mppi.mppi.create","title":"<code>create(nx, nu, noise_sigma, num_samples=100, horizon=15, lambda_=1.0, noise_mu=None, u_min=None, u_max=None, u_init=None, U_init=None, u_scale=1.0, u_per_command=1, step_dependent_dynamics=False, rollout_samples=1, rollout_var_cost=0.0, rollout_var_discount=0.95, sample_null_action=False, noise_abs_cost=False, key=None)</code>","text":"<p>Factory: create config + initial state.</p> Source code in <code>src/jax_mppi/mppi.py</code> <pre><code>def create(\n    nx: int,\n    nu: int,\n    noise_sigma: jax.Array,\n    num_samples: int = 100,\n    horizon: int = 15,\n    lambda_: float = 1.0,\n    noise_mu: Optional[jax.Array] = None,\n    u_min: Optional[jax.Array] = None,\n    u_max: Optional[jax.Array] = None,\n    u_init: Optional[jax.Array] = None,\n    U_init: Optional[jax.Array] = None,\n    u_scale: float = 1.0,\n    u_per_command: int = 1,\n    step_dependent_dynamics: bool = False,\n    rollout_samples: int = 1,\n    rollout_var_cost: float = 0.0,\n    rollout_var_discount: float = 0.95,\n    sample_null_action: bool = False,\n    noise_abs_cost: bool = False,\n    key: Optional[jax.Array] = None,\n) -&gt; Tuple[MPPIConfig, MPPIState]:\n    \"\"\"Factory: create config + initial state.\"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    config = MPPIConfig(\n        num_samples=num_samples,\n        horizon=horizon,\n        nx=nx,\n        nu=nu,\n        lambda_=lambda_,\n        u_scale=u_scale,\n        u_per_command=u_per_command,\n        step_dependent_dynamics=step_dependent_dynamics,\n        rollout_samples=rollout_samples,\n        rollout_var_cost=rollout_var_cost,\n        rollout_var_discount=rollout_var_discount,\n        sample_null_action=sample_null_action,\n        noise_abs_cost=noise_abs_cost,\n    )\n\n    # Initialize state variables\n    if noise_mu is None:\n        noise_mu = jnp.zeros(nu)\n\n    # Ensure noise_sigma is 2D\n    if noise_sigma.ndim == 1:\n        noise_sigma = jnp.diag(noise_sigma)\n\n    noise_sigma_inv = jnp.linalg.inv(noise_sigma)\n\n    if u_init is None:\n        u_init = jnp.zeros(nu)\n\n    if U_init is None:\n        U_init = jnp.tile(u_init, (horizon, 1))\n\n    mppi_state = MPPIState(\n        U=U_init,\n        u_init=u_init,\n        noise_mu=noise_mu,\n        noise_sigma=noise_sigma,\n        noise_sigma_inv=noise_sigma_inv,\n        u_min=None if u_min is None else jnp.array(u_min),\n        u_max=None if u_max is None else jnp.array(u_max),\n        key=key\n    )\n\n    return config, mppi_state\n</code></pre>"},{"location":"api/mppi/#jax_mppi.mppi.get_rollouts","title":"<code>get_rollouts(config, mppi_state, current_obs, dynamics, num_rollouts=1)</code>","text":"<p>Forward-simulate trajectories for visualization.</p> Source code in <code>src/jax_mppi/mppi.py</code> <pre><code>def get_rollouts(\n    config: MPPIConfig, mppi_state: MPPIState,\n    current_obs: jax.Array, dynamics: DynamicsFn,\n    num_rollouts: int = 1,\n) -&gt; jax.Array:\n    \"\"\"Forward-simulate trajectories for visualization.\"\"\"\n    noise, key = _sample_noise(\n        mppi_state.key,\n        num_rollouts,\n        config.horizon,\n        mppi_state.noise_mu,\n        mppi_state.noise_sigma,\n        sample_null_action=False,\n    )\n    perturbed_actions = mppi_state.U[None, :, :] + noise\n    scaled_actions = perturbed_actions * config.u_scale\n    scaled_actions = _bound_action(scaled_actions, mppi_state.u_min, mppi_state.u_max)\n\n    def rollout_single(actions, obs):\n        def step_fn(state, inputs):\n            t, action = inputs\n            next_state = _call_dynamics(dynamics, state, action, t, config.step_dependent_dynamics)\n            return next_state, _state_for_cost(next_state, config.nx)\n\n        ts = jnp.arange(config.horizon)\n        init_state = obs\n        _, states = jax.lax.scan(step_fn, init_state, (ts, actions))\n        init_out = _state_for_cost(init_state, config.nx)\n        return jnp.concatenate([init_out[None, :], states], axis=0)\n\n    if current_obs.ndim == 1:\n        rollouts = jax.vmap(lambda a: rollout_single(a, current_obs))(scaled_actions)\n    else:\n        rollouts = jax.vmap(\n            lambda obs: jax.vmap(lambda a: rollout_single(a, obs))(scaled_actions)\n        )(current_obs)\n\n    return rollouts\n</code></pre>"},{"location":"api/mppi/#jax_mppi.mppi.reset","title":"<code>reset(config, mppi_state, key)</code>","text":"<p>Reset nominal trajectory.</p> Source code in <code>src/jax_mppi/mppi.py</code> <pre><code>def reset(config: MPPIConfig, mppi_state: MPPIState, key: jax.Array) -&gt; MPPIState:\n    \"\"\"Reset nominal trajectory.\"\"\"\n    U_new = jnp.tile(mppi_state.u_init, (config.horizon, 1))\n    return replace(mppi_state, U=U_new, key=key)\n</code></pre>"},{"location":"api/smppi/","title":"SMPPI","text":"<p>Smooth MPPI (SMPPI) implementation in JAX.</p> <p>SMPPI operates in a lifted control space where the nominal trajectory U represents velocity/acceleration commands rather than direct actions. The actual action sequence is computed through numerical integration, with smoothness penalties on action differences.</p> <p>Reference: Based on pytorch_mppi SMPPI implementation</p>"},{"location":"api/smppi/#jax_mppi.smppi.SMPPIConfig","title":"<code>SMPPIConfig</code>  <code>dataclass</code>","text":"<p>Configuration for Smooth MPPI.</p> <p>Extends base MPPI with smoothness-specific parameters.</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>@dataclass(frozen=True)\nclass SMPPIConfig:\n    \"\"\"Configuration for Smooth MPPI.\n\n    Extends base MPPI with smoothness-specific parameters.\n    \"\"\"\n\n    # Base MPPI parameters\n    num_samples: int  # K\n    horizon: int  # T\n    nx: int\n    nu: int\n    lambda_: float\n    u_scale: float\n    u_per_command: int\n    step_dependent_dynamics: bool\n    rollout_samples: int  # M\n    rollout_var_cost: float\n    rollout_var_discount: float\n    sample_null_action: bool\n    noise_abs_cost: bool\n\n    # SMPPI-specific parameters\n    w_action_seq_cost: float  # Weight on smoothness penalty\n    delta_t: float  # Integration timestep\n</code></pre>"},{"location":"api/smppi/#jax_mppi.smppi.SMPPIState","title":"<code>SMPPIState</code>  <code>dataclass</code>","text":"<p>State for Smooth MPPI.</p> <p>Includes both velocity controls (U) and integrated actions (action_sequence).</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>@register_pytree_node_class\n@dataclass\nclass SMPPIState:\n    \"\"\"State for Smooth MPPI.\n\n    Includes both velocity controls (U) and integrated actions (action_sequence).\n    \"\"\"\n\n    # Base MPPI state\n    U: jax.Array  # (T, nu) velocity/acceleration commands\n    u_init: jax.Array  # (nu,) default velocity for shift\n    noise_mu: jax.Array  # (nu,)\n    noise_sigma: jax.Array  # (nu, nu)\n    noise_sigma_inv: jax.Array\n    u_min: Optional[jax.Array]  # Control velocity bounds\n    u_max: Optional[jax.Array]\n    key: jax.Array  # PRNG key\n\n    # SMPPI-specific state\n    action_sequence: jax.Array  # (T, nu) integrated actions\n    action_min: Optional[jax.Array]  # Action bounds\n    action_max: Optional[jax.Array]\n\n    def tree_flatten(self):\n        return (\n            (\n                self.U,\n                self.u_init,\n                self.noise_mu,\n                self.noise_sigma,\n                self.noise_sigma_inv,\n                self.u_min,\n                self.u_max,\n                self.key,\n                self.action_sequence,\n                self.action_min,\n                self.action_max,\n            ),\n            None,\n        )\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children):\n        return cls(*children)\n</code></pre>"},{"location":"api/smppi/#jax_mppi.smppi.command","title":"<code>command(config, smppi_state, current_obs, dynamics, running_cost, terminal_cost=None, shift=True)</code>","text":"<p>Compute optimal action using Smooth MPPI.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SMPPIConfig</code> <p>SMPPI configuration</p> required <code>smppi_state</code> <code>SMPPIState</code> <p>Current SMPPI state</p> required <code>current_obs</code> <code>Array</code> <p>(nx,) current observation/state</p> required <code>dynamics</code> <code>DynamicsFn</code> <p>Dynamics function</p> required <code>running_cost</code> <code>RunningCostFn</code> <p>Running cost function</p> required <code>terminal_cost</code> <code>Optional[TerminalCostFn]</code> <p>Optional terminal cost function</p> <code>None</code> <code>shift</code> <code>bool</code> <p>Whether to shift nominal trajectory after computing action</p> <code>True</code> <p>Returns:</p> Name Type Description <code>action</code> <code>Array</code> <p>(u_per_command * nu,) or (nu,) optimal action</p> <code>new_state</code> <code>SMPPIState</code> <p>Updated SMPPI state</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>def command(\n    config: SMPPIConfig,\n    smppi_state: SMPPIState,\n    current_obs: jax.Array,\n    dynamics: DynamicsFn,\n    running_cost: RunningCostFn,\n    terminal_cost: Optional[TerminalCostFn] = None,\n    shift: bool = True,\n) -&gt; Tuple[jax.Array, SMPPIState]:\n    \"\"\"Compute optimal action using Smooth MPPI.\n\n    Args:\n        config: SMPPI configuration\n        smppi_state: Current SMPPI state\n        current_obs: (nx,) current observation/state\n        dynamics: Dynamics function\n        running_cost: Running cost function\n        terminal_cost: Optional terminal cost function\n        shift: Whether to shift nominal trajectory after computing action\n\n    Returns:\n        action: (u_per_command * nu,) or (nu,) optimal action\n        new_state: Updated SMPPI state\n    \"\"\"\n    # Sample noise in velocity space\n    noise, new_key = _sample_noise(\n        smppi_state.key,\n        config.num_samples,\n        config.horizon,\n        smppi_state.noise_mu,\n        smppi_state.noise_sigma,\n        config.sample_null_action,\n    )\n\n    # Compute perturbed actions and effective noise\n    perturbed_actions, effective_noise = _compute_perturbed_actions_and_noise(\n        config, smppi_state, noise\n    )\n\n    # Compute rollout costs\n    rollout_costs = _compute_rollout_costs(\n        config,\n        current_obs,\n        perturbed_actions,\n        dynamics,\n        running_cost,\n        terminal_cost,\n    )\n\n    # Compute noise cost (in velocity space)\n    noise_costs = _compute_noise_cost(\n        effective_noise,\n        smppi_state.noise_sigma_inv,\n        config.noise_abs_cost,\n    )\n\n    # Compute smoothness cost\n    smoothness_costs = _compute_smoothness_cost(perturbed_actions, config)\n\n    # Total cost combines all three components\n    total_costs = rollout_costs + noise_costs + smoothness_costs\n\n    # Compute importance weights\n    weights = _compute_weights(total_costs, config.lambda_)\n\n    # Weighted update to control velocity\n    delta_U = jnp.sum(weights[:, None, None] * effective_noise, axis=0)\n    new_U = smppi_state.U + delta_U\n\n    # Integrate to update action sequence\n    new_action_sequence = smppi_state.action_sequence + new_U * config.delta_t\n\n    # Update state\n    new_state = replace(\n        smppi_state,\n        U=new_U,\n        action_sequence=new_action_sequence,\n        key=new_key,\n    )\n\n    # Shift nominal trajectory if requested\n    if shift:\n        new_state = _shift_nominal(new_state, shift_steps=config.u_per_command)\n\n    # Extract action to return\n    if config.u_per_command == 1:\n        action = new_action_sequence[0] * config.u_scale\n    else:\n        action = (\n            new_action_sequence[: config.u_per_command].reshape(-1) * config.u_scale\n        )\n\n    return action, new_state\n</code></pre>"},{"location":"api/smppi/#jax_mppi.smppi.create","title":"<code>create(nx, nu, noise_sigma, num_samples=100, horizon=15, lambda_=1.0, noise_mu=None, u_min=None, u_max=None, u_init=None, U_init=None, action_min=None, action_max=None, u_scale=1.0, u_per_command=1, step_dependent_dynamics=False, rollout_samples=1, rollout_var_cost=0.0, rollout_var_discount=0.95, sample_null_action=False, noise_abs_cost=False, w_action_seq_cost=1.0, delta_t=1.0, key=None)</code>","text":"<p>Create SMPPI configuration and initial state.</p> <p>Parameters:</p> Name Type Description Default <code>nx</code> <code>int</code> <p>State dimension</p> required <code>nu</code> <code>int</code> <p>Action dimension</p> required <code>noise_sigma</code> <code>Array</code> <p>(nu, nu) noise covariance matrix</p> required <code>num_samples</code> <code>int</code> <p>Number of MPPI samples (K)</p> <code>100</code> <code>horizon</code> <code>int</code> <p>Planning horizon (T)</p> <code>15</code> <code>lambda_</code> <code>float</code> <p>Temperature parameter for importance weighting</p> <code>1.0</code> <code>noise_mu</code> <code>Optional[Array]</code> <p>(nu,) noise mean (default: zeros)</p> <code>None</code> <code>u_min</code> <code>Optional[Array]</code> <p>(nu,) lower bounds on control velocity</p> <code>None</code> <code>u_max</code> <code>Optional[Array]</code> <p>(nu,) upper bounds on control velocity</p> <code>None</code> <code>u_init</code> <code>Optional[Array]</code> <p>(nu,) default control velocity for shift (default: zeros)</p> <code>None</code> <code>U_init</code> <code>Optional[Array]</code> <p>(T, nu) initial control velocity trajectory (default: zeros)</p> <code>None</code> <code>action_min</code> <code>Optional[Array]</code> <p>(nu,) lower bounds on actions</p> <code>None</code> <code>action_max</code> <code>Optional[Array]</code> <p>(nu,) upper bounds on actions</p> <code>None</code> <code>u_scale</code> <code>float</code> <p>Scale factor for control</p> <code>1.0</code> <code>u_per_command</code> <code>int</code> <p>Number of control steps per command</p> <code>1</code> <code>step_dependent_dynamics</code> <code>bool</code> <p>Whether dynamics depend on timestep</p> <code>False</code> <code>rollout_samples</code> <code>int</code> <p>Number of rollout samples for stochastic dynamics</p> <code>1</code> <code>rollout_var_cost</code> <code>float</code> <p>Variance cost weight</p> <code>0.0</code> <code>rollout_var_discount</code> <code>float</code> <p>Discount factor for variance cost</p> <code>0.95</code> <code>sample_null_action</code> <code>bool</code> <p>Whether to include null action in samples</p> <code>False</code> <code>noise_abs_cost</code> <code>bool</code> <p>Use absolute value cost for noise</p> <code>False</code> <code>w_action_seq_cost</code> <code>float</code> <p>Weight on smoothness penalty</p> <code>1.0</code> <code>delta_t</code> <code>float</code> <p>Integration timestep</p> <code>1.0</code> <code>key</code> <code>Optional[Array]</code> <p>PRNG key (default: create new)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>config</code> <code>SMPPIConfig</code> <p>SMPPI configuration</p> <code>state</code> <code>SMPPIState</code> <p>SMPPI initial state</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>def create(\n    nx: int,\n    nu: int,\n    noise_sigma: jax.Array,\n    num_samples: int = 100,\n    horizon: int = 15,\n    lambda_: float = 1.0,\n    noise_mu: Optional[jax.Array] = None,\n    u_min: Optional[jax.Array] = None,\n    u_max: Optional[jax.Array] = None,\n    u_init: Optional[jax.Array] = None,\n    U_init: Optional[jax.Array] = None,\n    action_min: Optional[jax.Array] = None,\n    action_max: Optional[jax.Array] = None,\n    u_scale: float = 1.0,\n    u_per_command: int = 1,\n    step_dependent_dynamics: bool = False,\n    rollout_samples: int = 1,\n    rollout_var_cost: float = 0.0,\n    rollout_var_discount: float = 0.95,\n    sample_null_action: bool = False,\n    noise_abs_cost: bool = False,\n    w_action_seq_cost: float = 1.0,\n    delta_t: float = 1.0,\n    key: Optional[jax.Array] = None,\n) -&gt; Tuple[SMPPIConfig, SMPPIState]:\n    \"\"\"Create SMPPI configuration and initial state.\n\n    Args:\n        nx: State dimension\n        nu: Action dimension\n        noise_sigma: (nu, nu) noise covariance matrix\n        num_samples: Number of MPPI samples (K)\n        horizon: Planning horizon (T)\n        lambda_: Temperature parameter for importance weighting\n        noise_mu: (nu,) noise mean (default: zeros)\n        u_min: (nu,) lower bounds on control velocity\n        u_max: (nu,) upper bounds on control velocity\n        u_init: (nu,) default control velocity for shift (default: zeros)\n        U_init: (T, nu) initial control velocity trajectory (default: zeros)\n        action_min: (nu,) lower bounds on actions\n        action_max: (nu,) upper bounds on actions\n        u_scale: Scale factor for control\n        u_per_command: Number of control steps per command\n        step_dependent_dynamics: Whether dynamics depend on timestep\n        rollout_samples: Number of rollout samples for stochastic dynamics\n        rollout_var_cost: Variance cost weight\n        rollout_var_discount: Discount factor for variance cost\n        sample_null_action: Whether to include null action in samples\n        noise_abs_cost: Use absolute value cost for noise\n        w_action_seq_cost: Weight on smoothness penalty\n        delta_t: Integration timestep\n        key: PRNG key (default: create new)\n\n    Returns:\n        config: SMPPI configuration\n        state: SMPPI initial state\n    \"\"\"\n    # Initialize defaults\n    if noise_mu is None:\n        noise_mu = jnp.zeros(nu)\n    if u_init is None:\n        u_init = jnp.zeros(nu)\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    # Scale bounds\n    u_min_scaled = _scaled_bounds(u_min, u_scale)\n    u_max_scaled = _scaled_bounds(u_max, u_scale)\n    action_min_scaled = _scaled_bounds(action_min, u_scale)\n    action_max_scaled = _scaled_bounds(action_max, u_scale)\n\n    # Symmetric bounds inference\n    if action_min_scaled is not None and action_max_scaled is None:\n        action_max_scaled = -action_min_scaled\n    if action_max_scaled is not None and action_min_scaled is None:\n        action_min_scaled = -action_max_scaled\n\n    # Initialize control velocity trajectory (U starts at zeros for SMPPI)\n    if U_init is None:\n        U = jnp.zeros((horizon, nu))\n        action_sequence = jnp.zeros((horizon, nu))\n    else:\n        U = jnp.zeros_like(U_init)  # Start with zero velocity\n        action_sequence = U_init.copy()  # U_init is interpreted as initial actions\n\n    # Compute noise covariance inverse\n    noise_sigma_inv = jnp.linalg.inv(noise_sigma)\n\n    # Create config\n    config = SMPPIConfig(\n        num_samples=num_samples,\n        horizon=horizon,\n        nx=nx,\n        nu=nu,\n        lambda_=lambda_,\n        u_scale=u_scale,\n        u_per_command=u_per_command,\n        step_dependent_dynamics=step_dependent_dynamics,\n        rollout_samples=rollout_samples,\n        rollout_var_cost=rollout_var_cost,\n        rollout_var_discount=rollout_var_discount,\n        sample_null_action=sample_null_action,\n        noise_abs_cost=noise_abs_cost,\n        w_action_seq_cost=w_action_seq_cost,\n        delta_t=delta_t,\n    )\n\n    # Create state\n    state = SMPPIState(\n        U=U,\n        u_init=u_init,\n        noise_mu=noise_mu,\n        noise_sigma=noise_sigma,\n        noise_sigma_inv=noise_sigma_inv,\n        u_min=u_min_scaled,\n        u_max=u_max_scaled,\n        key=key,\n        action_sequence=action_sequence,\n        action_min=action_min_scaled,\n        action_max=action_max_scaled,\n    )\n\n    return config, state\n</code></pre>"},{"location":"api/smppi/#jax_mppi.smppi.get_rollouts","title":"<code>get_rollouts(config, smppi_state, current_obs, dynamics, num_rollouts=1)</code>","text":"<p>Generate rollout trajectories using current action sequence.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SMPPIConfig</code> <p>SMPPI configuration</p> required <code>smppi_state</code> <code>SMPPIState</code> <p>Current SMPPI state</p> required <code>current_obs</code> <code>Array</code> <p>(nx,) or (batch, nx) current state</p> required <code>dynamics</code> <code>DynamicsFn</code> <p>Dynamics function</p> required <code>num_rollouts</code> <code>int</code> <p>Number of rollout samples</p> <code>1</code> <p>Returns:</p> Name Type Description <code>rollouts</code> <code>Array</code> <p>(num_rollouts, horizon+1, nx) state trajectories</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>def get_rollouts(\n    config: SMPPIConfig,\n    smppi_state: SMPPIState,\n    current_obs: jax.Array,\n    dynamics: DynamicsFn,\n    num_rollouts: int = 1,\n) -&gt; jax.Array:\n    \"\"\"Generate rollout trajectories using current action sequence.\n\n    Args:\n        config: SMPPI configuration\n        smppi_state: Current SMPPI state\n        current_obs: (nx,) or (batch, nx) current state\n        dynamics: Dynamics function\n        num_rollouts: Number of rollout samples\n\n    Returns:\n        rollouts: (num_rollouts, horizon+1, nx) state trajectories\n    \"\"\"\n\n    def single_rollout(carry, _):\n        state = carry\n\n        def step_fn(s, inputs):\n            t, action = inputs\n            next_s = _call_dynamics(\n                dynamics, s, action, t, config.step_dependent_dynamics\n            )\n            next_s_trimmed = _state_for_cost(next_s, config.nx)\n            return next_s, next_s_trimmed\n\n        ts = jnp.arange(config.horizon)\n        _, trajectory = jax.lax.scan(step_fn, state, (ts, smppi_state.action_sequence))\n\n        # Prepend initial state\n        initial_state = _state_for_cost(state, config.nx)\n        full_trajectory = jnp.concatenate([initial_state[None, :], trajectory], axis=0)\n\n        return state, full_trajectory\n\n    # Handle batched or single state\n    if current_obs.ndim == 1:\n        obs_batch = current_obs[None, :]\n    else:\n        obs_batch = current_obs\n\n    # Generate multiple rollouts\n    _, rollouts = jax.lax.scan(single_rollout, obs_batch[0], jnp.arange(num_rollouts))\n\n    return rollouts\n</code></pre>"},{"location":"api/smppi/#jax_mppi.smppi.reset","title":"<code>reset(config, smppi_state, key)</code>","text":"<p>Reset SMPPI state with new random key.</p> Source code in <code>src/jax_mppi/smppi.py</code> <pre><code>def reset(config: SMPPIConfig, smppi_state: SMPPIState, key: jax.Array) -&gt; SMPPIState:\n    \"\"\"Reset SMPPI state with new random key.\"\"\"\n    # Reset both U and action_sequence to zeros\n    return replace(\n        smppi_state,\n        U=jnp.zeros_like(smppi_state.U),\n        action_sequence=jnp.zeros_like(smppi_state.action_sequence),\n        key=key,\n    )\n</code></pre>"},{"location":"api/types/","title":"Types","text":""},{"location":"examples/pendulum/","title":"Pendulum Swing-Up","text":"<p>This example demonstrates how to use <code>jax_mppi</code> to control an inverted pendulum. The goal is to swing the pendulum up from a hanging position and stabilize it at the top.</p>"},{"location":"examples/pendulum/#code","title":"Code","text":"<p>The full example code is available in <code>examples/pendulum.py</code>.</p>"},{"location":"examples/pendulum/#dynamics","title":"Dynamics","text":"<p>The pendulum dynamics are defined as a pure function:</p> <pre><code>def pendulum_dynamics(state: jax.Array, action: jax.Array) -&gt; jax.Array:\n    \"\"\"Pendulum dynamics.\n\n    State: [theta, theta_dot]\n        theta: angle from upright (0 = upright, pi = hanging down)\n        theta_dot: angular velocity\n    Action: [torque]\n        torque: applied torque (control input)\n    \"\"\"\n    g = 10.0  # gravity\n    m = 1.0  # mass\n    l = 1.0  # length\n    dt = 0.05  # timestep\n\n    theta, theta_dot = state[0], state[1]\n    torque = action[0]\n\n    # Clip torque to reasonable bounds\n    torque = jnp.clip(torque, -2.0, 2.0)\n\n    # Pendulum dynamics: theta_ddot = (torque - m*g*l*sin(theta)) / (m*l^2)\n    theta_ddot = (torque - m * g * l * jnp.sin(theta)) / (m * l * l)\n\n    # Euler integration\n    theta_dot_next = theta_dot + theta_ddot * dt\n    theta_next = theta + theta_dot_next * dt\n\n    # Normalize angle to [-pi, pi]\n    theta_next = ((theta_next + jnp.pi) % (2 * jnp.pi)) - jnp.pi\n\n    return jnp.array([theta_next, theta_dot_next])\n</code></pre>"},{"location":"examples/pendulum/#cost-function","title":"Cost Function","text":"<p>The running cost penalizes deviation from the upright position and high control effort:</p> <pre><code>def pendulum_cost(state: jax.Array, action: jax.Array) -&gt; jax.Array:\n    theta, theta_dot = state[0], state[1]\n    torque = action[0]\n\n    # Cost for being away from upright (theta=0)\n    angle_cost = theta**2\n\n    # Cost for high angular velocity\n    velocity_cost = 0.1 * theta_dot**2\n\n    # Cost for using torque\n    control_cost = 0.01 * torque**2\n\n    return angle_cost + velocity_cost + control_cost\n</code></pre>"},{"location":"examples/pendulum/#running-the-example","title":"Running the Example","text":"<p>You can run the example using:</p> <pre><code>python examples/pendulum.py --visualize\n</code></pre>"},{"location":"plan/porting_pytorch_jax/","title":"JAX MPPI Implementation Plan","text":"<p>Port <code>pytorch_mppi</code> to JAX, producing a functional, JIT-compilable MPPI library.</p>"},{"location":"plan/porting_pytorch_jax/#status-jan-31-2026","title":"Status (Jan 31, 2026)","text":"<p>Overall Progress: Phase 4 complete (Kernel MPPI fully implemented and tested).</p>"},{"location":"plan/porting_pytorch_jax/#implementation-status-by-phase","title":"Implementation Status by Phase","text":"<ul> <li>Phase 1: Core MPPI \u2705 COMPLETE</li> <li>353 lines implemented in <code>src/jax_mppi/mppi.py</code></li> <li>All core features from pytorch_mppi ported</li> <li> <p>115 lines of unit tests in <code>tests/test_mppi.py</code></p> </li> <li> <p>Phase 2: Pendulum Integration \u2705 COMPLETE</p> </li> <li>270 lines in <code>examples/pendulum.py</code> (full-featured example with CLI)</li> <li>282 lines in <code>tests/test_pendulum.py</code> (8 comprehensive integration tests)</li> <li> <p>All tests passing, swing-up and stabilization verified</p> </li> <li> <p>Phase 3: Smooth MPPI (SMPPI) \u2705 COMPLETE</p> </li> <li>634 lines implemented in <code>src/jax_mppi/smppi.py</code></li> <li>All SMPPI features: action_sequence, smoothness cost, dual bounds, integration</li> <li>580 lines in <code>tests/test_smppi.py</code> (18 comprehensive tests)</li> <li> <p>All tests passing</p> </li> <li> <p>Phase 4: Kernel MPPI (KMPPI) \u2705 COMPLETE</p> </li> <li>660 lines implemented in <code>src/jax_mppi/kmppi.py</code></li> <li>RBFKernel, kernel interpolation, control point optimization</li> <li>595 lines in <code>tests/test_kmppi.py</code> (23 comprehensive tests)</li> <li> <p>All tests passing (53/53 total tests pass)</p> </li> <li> <p>Phase 5: Smooth Comparison Example \ud83d\udd34 PENDING</p> </li> <li> <p>File: <code>examples/smooth_comparison.py</code> (not created)</p> </li> <li> <p>Phase 6: Autotuning \ud83d\udd34 PENDING</p> </li> <li>File: <code>src/jax_mppi/autotune.py</code> (not created)</li> </ul>"},{"location":"plan/porting_pytorch_jax/#package-size-comparison","title":"Package Size Comparison","text":"Package Core Code Tests Examples Total pytorch_mppi 1214 lines ~500 lines ~800 lines ~2500 lines jax_mppi (current) 1670 lines 1572 lines 270 lines 3512 lines Completion % 138% 314% 34% 140%"},{"location":"plan/porting_pytorch_jax/#feature-parity-matrix","title":"Feature Parity Matrix","text":"Feature pytorch_mppi jax_mppi Status Core MPPI Algorithm \u2713 \u2713 \u2705 Complete Basic sampling &amp; weighting \u2713 \u2713 \u2705 Control bounds (u_min/u_max) \u2713 \u2713 \u2705 Control scaling (u_scale) \u2713 \u2713 \u2705 Partial updates (u_per_command) \u2713 \u2713 \u2705 Step-dependent dynamics \u2713 \u2713 \u2705 Stochastic dynamics (rollout_samples) \u2713 \u2713 \u2705 Sample null action \u2713 \u2713 \u2705 Noise absolute cost \u2713 \u2713 \u2705 Terminal cost function \u2713 \u2713 \u2705 Shift nominal trajectory \u2713 \u2713 \u2705 Get rollouts (visualization) \u2713 \u2713 \u2705 Reset controller \u2713 \u2713 \u2705 Smooth MPPI (SMPPI) \u2713 \u2713 \u2705 Complete Action sequence tracking \u2713 \u2713 \u2705 Smoothness penalty \u2713 \u2713 \u2705 Separate action/control bounds \u2713 \u2713 \u2705 Delta_t integration \u2713 \u2713 \u2705 Shift with continuity \u2713 \u2713 \u2705 Kernel MPPI (KMPPI) \u2713 \u2713 \u2705 Complete Kernel interpolation \u2713 \u2713 \u2705 RBF kernel \u2713 \u2713 \u2705 Support point optimization \u2713 \u2713 \u2705 Time grid management (Tk/Hs) \u2713 \u2713 \u2705 Solve-based interpolation \u2713 \u2713 \u2705 Autotuning \u2713 \u2717 \ud83d\udd34 Not started CMA-ES local tuning \u2713 \u2717 \ud83d\udd34 Parameter search \u2713 \u2717 \ud83d\udd34 Examples Pendulum swing-up \u2713 \u2713 \u2705 Complete Pendulum with learned dynamics \u2713 \u2717 \ud83d\udd34 Planned Smooth MPPI comparison \u2713 \u2717 \ud83d\udd34 Planned Autotuning example \u2713 \u2717 \ud83d\udd34 Planned"},{"location":"plan/porting_pytorch_jax/#current-file-structure","title":"Current File Structure","text":"<pre><code>jax_mppi/\n\u251c\u2500\u2500 pyproject.toml              \u2705 Exists\n\u251c\u2500\u2500 README.md                   \u2705 Exists\n\u251c\u2500\u2500 LICENSE                     \u2705 Exists  \n\u251c\u2500\u2500 src/jax_mppi/\n\u2502   \u251c\u2500\u2500 __init__.py            \u2705 Exists (14 lines)\n\u2502   \u251c\u2500\u2500 types.py               \u2705 Exists (9 lines)\n\u2502   \u251c\u2500\u2500 mppi.py                \u2705 Exists (353 lines) - COMPLETE\n\u2502   \u251c\u2500\u2500 smppi.py               \u2705 Exists (634 lines) - COMPLETE\n\u2502   \u251c\u2500\u2500 kmppi.py               \u2705 Exists (660 lines) - COMPLETE\n\u2502   \u2514\u2500\u2500 autotune.py            \ud83d\udd34 Not created\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_mppi.py           \u2705 Exists (115 lines) - COMPLETE\n\u2502   \u251c\u2500\u2500 test_pendulum.py       \u2705 Exists (282 lines) - COMPLETE\n\u2502   \u251c\u2500\u2500 test_smppi.py          \u2705 Exists (580 lines) - COMPLETE\n\u2502   \u2514\u2500\u2500 test_kmppi.py          \u2705 Exists (595 lines) - COMPLETE\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 pendulum.py            \u2705 Exists (270 lines) - COMPLETE\n\u2502   \u251c\u2500\u2500 pendulum_approximate.py \ud83d\udd34 Not created\n\u2502   \u2514\u2500\u2500 smooth_comparison.py   \ud83d\udd34 Not created\n\u2514\u2500\u2500 docs/\n    \u2514\u2500\u2500 plan/\n        \u2514\u2500\u2500 porting_pytorch_jax.md \u2705 This file\n</code></pre>"},{"location":"plan/porting_pytorch_jax/#recommended-next-steps","title":"Recommended Next Steps","text":"<p>Priority Order:</p> <ol> <li>Phase 3: SMPPI Implementation (High Priority)</li> <li>Core functionality that adds smoothness to control</li> <li>Estimated ~250-300 lines for smppi.py</li> <li>Estimated ~150-200 lines for tests</li> <li> <p>Reference: <code>../pytorch_mppi/src/pytorch_mppi/mppi.py</code> (SMPPI class)</p> </li> <li> <p>Phase 4: KMPPI Implementation (High Priority)</p> </li> <li>Novel contribution with kernel interpolation</li> <li>Estimated ~300-350 lines for kmppi.py</li> <li>Estimated ~150-200 lines for tests</li> <li> <p>Reference: <code>../pytorch_mppi/src/pytorch_mppi/mppi.py</code> (KMPPI class)</p> </li> <li> <p>Phase 5: Smooth Comparison Example (Medium Priority)</p> </li> <li>Demonstrates value of SMPPI and KMPPI</li> <li>Estimated ~200-250 lines</li> <li> <p>Reference: <code>../pytorch_mppi/tests/smooth_mppi.py</code></p> </li> <li> <p>Additional Examples (Low Priority)</p> </li> <li>Pendulum with learned dynamics</li> <li> <p>More complex environments</p> </li> <li> <p>Phase 6: Autotuning (Optional/Stretch)</p> </li> <li>Advanced feature for hyperparameter optimization</li> <li>Estimated ~300-400 lines</li> <li>Reference: <code>../pytorch_mppi/src/pytorch_mppi/autotune.py</code></li> </ol>"},{"location":"plan/porting_pytorch_jax/#design-decisions","title":"Design Decisions","text":""},{"location":"plan/porting_pytorch_jax/#api-style-functional-with-dataclass-state-containers","title":"API Style: Functional with dataclass state containers","text":"<p>Use <code>@jax.tree_util.register_dataclass</code> (or <code>flax.struct.dataclass</code>) to hold MPPI state (nominal trajectory <code>U</code>, PRNG key, config). All core functions are pure: <code>command(state, mppi_state) -&gt; (action, mppi_state)</code>.</p> <p>Rationale: Idiomatic JAX \u2014 pure functions compose with <code>jit</code>, <code>vmap</code>, <code>grad</code>. No mutable <code>self</code>. Avoids heavyweight dependencies like Equinox for what is fundamentally a numerical algorithm.</p>"},{"location":"plan/porting_pytorch_jax/#key-jax-mappings-from-pytorch","title":"Key JAX mappings from PyTorch","text":"PyTorch JAX <code>torch.distributions.MultivariateNormal</code> <code>jax.random.multivariate_normal</code> <code>tensor.to(device)</code> <code>jax.device_put</code> / automatic Python for-loop over horizon <code>jax.lax.scan</code> <code>@handle_batch_input</code> decorator <code>jax.vmap</code> <code>torch.roll</code> <code>jnp.roll</code> <code>torch.linalg.solve</code> <code>jnp.linalg.solve</code> In-place mutation (<code>self.U = ...</code>) Return new state (pytree)"},{"location":"plan/porting_pytorch_jax/#notes-from-pytorch_mppi-review-jan-2026","title":"Notes from <code>../pytorch_mppi</code> review (Jan 2026)","text":"<p>Actionable parity items to carry over: - SMPPI semantics: maintains <code>action_sequence</code> separately from lifted control <code>U</code>; integrates with <code>delta_t</code>; smoothness cost from <code>diff(action_sequence)</code>. - SMPPI bounds: support <code>action_min</code>/<code>action_max</code> distinct from <code>u_min</code>/<code>u_max</code> (control-derivative bounds). - KMPPI internals: keep <code>theta</code> as control points; build <code>Tk</code>/<code>Hs</code> time grids; kernel interpolation via <code>solve(Ktktk, K)</code>; batch interpolation with <code>vmap</code>. - Sampling options: <code>rollout_samples</code> (M), <code>sample_null_action</code>, <code>noise_abs_cost</code> (abs(noise) in action cost). - Rollouts: <code>get_rollouts</code> handles <code>state</code> batch and dynamics that may augment state (take first <code>nx</code>).</p>"},{"location":"plan/porting_pytorch_jax/#package-structure","title":"Package Structure","text":"<pre><code>jax_mppi/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 src/jax_mppi/\n\u2502   \u251c\u2500\u2500 __init__.py          # Public API exports\n\u2502   \u251c\u2500\u2500 mppi.py              # Core MPPI (MPPIConfig, MPPIState, command, reset, etc.)\n\u2502   \u251c\u2500\u2500 smppi.py             # Smooth MPPI variant\n\u2502   \u251c\u2500\u2500 kmppi.py             # Kernel MPPI variant + TimeKernel / RBFKernel\n\u2502   \u251c\u2500\u2500 types.py             # Type aliases, protocols for Dynamics/Cost callables\n\u2502   \u2514\u2500\u2500 autotune.py          # Autotuning (CMA-ES wrapper, parameter search)\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_mppi.py         # Unit tests for core MPPI\n\u2502   \u251c\u2500\u2500 test_smppi.py        # Unit tests for SMPPI\n\u2502   \u251c\u2500\u2500 test_kmppi.py        # Unit tests for KMPPI\n\u2502   \u2514\u2500\u2500 test_pendulum.py     # Integration test with pendulum env\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 pendulum.py          # Gym pendulum with true dynamics\n\u2502   \u251c\u2500\u2500 pendulum_approximate.py  # Learned dynamics\n\u2502   \u2514\u2500\u2500 smooth_comparison.py # MPPI vs SMPPI vs KMPPI\n\u2514\u2500\u2500 docs/\n    \u2514\u2500\u2500 plan/\n</code></pre>"},{"location":"plan/porting_pytorch_jax/#phased-implementation","title":"Phased Implementation","text":""},{"location":"plan/porting_pytorch_jax/#phase-1-project-scaffolding-core-mppi","title":"Phase 1: Project scaffolding + Core MPPI","text":"<p>Files: <code>pyproject.toml</code>, <code>src/jax_mppi/types.py</code>, <code>src/jax_mppi/mppi.py</code>, <code>src/jax_mppi/__init__.py</code></p> <ol> <li> <p><code>pyproject.toml</code> \u2014 project metadata, deps: <code>jax[cuda13]</code>, <code>jaxlib</code>, optional <code>gymnasium</code> for examples.</p> </li> <li> <p><code>types.py</code> \u2014 Type definitions:    <code>python    # Dynamics: (state, action) -&gt; next_state  or  (state, action, t) -&gt; next_state    DynamicsFn = Callable[..., jax.Array]    # Cost: (state, action) -&gt; scalar_cost  or  (state, action, t) -&gt; scalar_cost    RunningCostFn = Callable[..., jax.Array]    # Terminal: (states, actions) -&gt; scalar_cost    TerminalCostFn = Callable[[jax.Array, jax.Array], jax.Array]</code></p> </li> <li> <p><code>mppi.py</code> \u2014 Core implementation:</p> </li> </ol> <p>Data structures (registered as JAX pytrees):    ```python    @dataclass    class MPPIConfig:        # Static config (not traced through JAX)        num_samples: int       # K        horizon: int           # T        nx: int        nu: int        lambda_: float        u_scale: float        u_per_command: int        step_dependent_dynamics: bool        rollout_samples: int   # M        rollout_var_cost: float        rollout_var_discount: float        sample_null_action: bool        noise_abs_cost: bool</p> <p>@dataclass    class MPPIState:        # Dynamic state (carried through JAX transforms)        U: jax.Array           # (T, nu) nominal trajectory        u_init: jax.Array      # (nu,) default action for shift        noise_mu: jax.Array    # (nu,)        noise_sigma: jax.Array # (nu, nu)        noise_sigma_inv: jax.Array        u_min: jax.Array | None        u_max: jax.Array | None        key: jax.Array         # PRNG key    ```</p> <p>Functions:    ```python    def create(        nx, nu, noise_sigma, num_samples=100, horizon=15, lambda_=1.0,        noise_mu=None, u_min=None, u_max=None, u_init=None, U_init=None,        u_scale=1, u_per_command=1, step_dependent_dynamics=False,        rollout_samples=1, rollout_var_cost=0., rollout_var_discount=0.95,        sample_null_action=False, noise_abs_cost=False, key=None,    ) -&gt; tuple[MPPIConfig, MPPIState]:        \"\"\"Factory: create config + initial state.\"\"\"</p> <p>def command(        config: MPPIConfig,        mppi_state: MPPIState,        current_obs: jax.Array,        dynamics: DynamicsFn,        running_cost: RunningCostFn,        terminal_cost: TerminalCostFn | None = None,        shift: bool = True,    ) -&gt; tuple[jax.Array, MPPIState]:        \"\"\"Compute optimal action and return updated state.\"\"\"</p> <p>def reset(config: MPPIConfig, mppi_state: MPPIState, key: jax.Array) -&gt; MPPIState:        \"\"\"Reset nominal trajectory.\"\"\"</p> <p>def get_rollouts(        config: MPPIConfig, mppi_state: MPPIState,        current_obs: jax.Array, dynamics: DynamicsFn,        num_rollouts: int = 1,    ) -&gt; jax.Array:        \"\"\"Forward-simulate trajectories for visualization.\"\"\"    ```</p> <p>Internal functions (all JIT-compatible):    - <code>_shift_nominal(mppi_state) -&gt; MPPIState</code> \u2014 <code>jnp.roll</code> + set last to <code>u_init</code>    - <code>_sample_noise(key, K, T, noise_mu, noise_sigma) -&gt; (noise, new_key)</code> \u2014 sample from multivariate normal    - <code>_compute_rollout_costs(config, current_obs, perturbed_actions, dynamics, running_cost, terminal_cost)</code> \u2014 uses <code>jax.lax.scan</code> over horizon, <code>jax.vmap</code> over K samples    - <code>_compute_weights(costs, lambda_)</code> \u2014 softmax importance weighting    - <code>_bound_action(action, u_min, u_max)</code> \u2014 <code>jnp.clip</code></p> <p>Key JAX patterns:    - Rollout loop: <code>jax.lax.scan</code> with carry = <code>(state,)</code>, xs = <code>actions[t]</code>    - Batch over K samples: <code>jax.vmap(_single_rollout, in_axes=(0, None, ...))</code>    - Batch over M rollout samples (stochastic dynamics): nested vmap or scan    - All internal functions decorated with <code>@jax.jit</code> or called inside a top-level jitted <code>command</code></p> <ol> <li>Unit test: <code>tests/test_mppi.py</code></li> <li>Test <code>create()</code> produces valid config/state</li> <li>Test <code>command()</code> returns correct shape</li> <li>Test cost reduction over iterations on simple 1D problem</li> <li>Test bounds are respected</li> </ol>"},{"location":"plan/porting_pytorch_jax/#phase-2-pendulum-example-integration-test","title":"Phase 2: Pendulum example (integration test)","text":"<p>Files: <code>examples/pendulum.py</code>, <code>tests/test_pendulum.py</code></p> <ol> <li>Implement pendulum dynamics as a pure JAX function (no gym dependency for core test)</li> <li>Run MPPI loop, verify convergence (swing-up or stabilization)</li> <li>Optional: gym rendering wrapper for visualization</li> </ol>"},{"location":"plan/porting_pytorch_jax/#phase-3-smooth-mppi-smppi","title":"Phase 3: Smooth MPPI (SMPPI)","text":"<p>Files: <code>src/jax_mppi/smppi.py</code>, <code>tests/test_smppi.py</code></p> <ol> <li> <p>Data structures: <code>python    @dataclass    class SMPPIState(MPPIState):        action_sequence: jax.Array  # (T, nu) actual actions        w_action_seq_cost: float        delta_t: float        action_min: jax.Array | None        action_max: jax.Array | None</code></p> </li> <li> <p>Functions: Same API as <code>mppi.py</code> but with:</p> </li> <li><code>_shift_nominal</code> shifts both <code>U</code> (velocity) and <code>action_sequence</code></li> <li><code>_compute_perturbed_actions</code> integrates velocity to get actions</li> <li><code>_compute_total_cost</code> adds smoothness penalty: <code>||diff(actions)||^2</code></li> <li><code>reset()</code> zeros both <code>U</code> and <code>action_sequence</code></li> <li> <p><code>change_horizon()</code> keeps both <code>U</code> and <code>action_sequence</code> in sync (truncate/extend)</p> </li> <li> <p>Test: Verify smoother trajectories than base MPPI on 2D navigation</p> </li> </ol>"},{"location":"plan/porting_pytorch_jax/#phase-4-kernel-mppi-kmppi","title":"Phase 4: Kernel MPPI (KMPPI)","text":"<p>Files: <code>src/jax_mppi/kmppi.py</code>, <code>tests/test_kmppi.py</code></p> <ol> <li>Kernel abstractions:    ```python    def rbf_kernel(t, tk, sigma=1.0):        d = jnp.sum((t[:, None] - tk) ** 2, axis=-1)        return jnp.exp(-d / (2 * sigma ** 2 + 1e-8))</li> </ol> <p>def kernel_interpolate(t, tk, coeffs, kernel_fn):        K_t_tk = kernel_fn(t, tk)        K_tk_tk = kernel_fn(tk, tk)        weights = jnp.linalg.solve(K_tk_tk, K_t_tk.T).T        return weights @ coeffs    ```</p> <ol> <li> <p>Data structures: <code>python    @dataclass    class KMPPIState(MPPIState):        theta: jax.Array         # (num_support_pts, nu)        num_support_pts: int</code></p> </li> <li> <p>Functions: Override <code>_compute_perturbed_actions</code> to sample sparse + interpolate. Update <code>theta</code> instead of <code>U</code>.</p> </li> <li>Build <code>Tk</code> and <code>Hs</code> time grids on init and on horizon changes</li> <li>Use <code>kernel_interpolate()</code> with <code>solve(Ktktk, K)</code> (avoid explicit inverse)</li> <li> <p>Batch interpolate with <code>jax.vmap</code> for K samples</p> </li> <li> <p>Test: Verify fewer parameters produce smooth trajectories</p> </li> </ol>"},{"location":"plan/porting_pytorch_jax/#phase-5-smooth-comparison-example","title":"Phase 5: Smooth comparison example","text":"<p>Files: <code>examples/smooth_comparison.py</code></p> <ul> <li>Side-by-side MPPI vs SMPPI vs KMPPI on 2D navigation</li> <li>Plot trajectories and control signals</li> </ul>"},{"location":"plan/porting_pytorch_jax/#phase-6-autotuning-stretch-goal","title":"Phase 6: Autotuning (stretch goal)","text":"<p>Files: <code>src/jax_mppi/autotune.py</code></p> <ul> <li>Wrap CMA-ES (<code>cmaes</code> or <code>evosax</code> for JAX-native) for sigma/lambda/horizon tuning</li> <li>Simpler than pytorch_mppi's framework \u2014 skip Ray Tune and QD initially</li> <li>Functional API: <code>tune_step(eval_fn, params, optimizer_state) -&gt; (params, optimizer_state)</code></li> </ul>"},{"location":"plan/porting_pytorch_jax/#verification-strategy","title":"Verification Strategy","text":"<ol> <li>Unit tests (per phase): <code>pytest tests/</code> \u2014 shape checks, cost reduction, bounds</li> <li>Pendulum benchmark: Compare convergence (total reward) against pytorch_mppi on same scenario</li> <li>JIT correctness: Ensure <code>jax.jit(command)</code> produces identical results to non-jitted version</li> <li>Performance: Benchmark <code>command()</code> latency vs pytorch_mppi (JAX should win after warmup due to XLA compilation)</li> <li>Smooth variants: Visual comparison of trajectory smoothness</li> </ol>"},{"location":"plan/porting_pytorch_jax/#test-setup-options-src-layout","title":"Test setup options (src layout)","text":"<p>IMPORTANT: You should always use the virtual environment. To run the tests and all of the other python files.</p> <ul> <li>Option A: add a <code>tests/conftest.py</code> to insert <code>src</code> into <code>sys.path</code>.</li> <li>Option B: run tests after <code>uv pip install -e .</code> (editable install).</li> </ul>"},{"location":"plan/porting_pytorch_jax/#dependencies","title":"Dependencies","text":"<p>Core: <code>jax[cuda13]</code>, <code>jaxlib</code>, <code>numpy</code> Testing: <code>pytest</code>, <code>gymnasium[classic_control]</code> Autotuning (optional): <code>cmaes</code> or <code>evosax</code> Examples (optional): <code>matplotlib</code>, <code>gymnasium</code></p>"},{"location":"plan/porting_pytorch_jax/#actionable-task-checklist","title":"Actionable Task Checklist","text":""},{"location":"plan/porting_pytorch_jax/#core-mppi-phase-1","title":"Core MPPI (Phase 1)","text":"<ul> <li>[x] Mirror <code>pytorch_mppi</code> signature flags: <code>rollout_samples</code>, <code>sample_null_action</code>, <code>noise_abs_cost</code>.</li> <li>[x] Implement <code>get_rollouts</code> handling: accept single or batched <code>state</code>; allow dynamics that augment state (take <code>:nx</code>).</li> <li>[x] Add <code>shift_nominal_trajectory</code> via <code>jnp.roll</code> + <code>u_init</code> fill.</li> <li>[x] Implement action cost with optional <code>abs(noise)</code> branch.</li> <li>[x] Add <code>u_per_command</code> slicing and <code>u_scale</code> application in <code>command</code>.</li> </ul>"},{"location":"plan/porting_pytorch_jax/#smppi-phase-3","title":"SMPPI (Phase 3)","text":"<ul> <li>[x] Carry <code>action_sequence</code> in state and integrate <code>U</code> with <code>delta_t</code>.</li> <li>[x] Implement distinct action bounds (<code>action_min</code>/<code>action_max</code>) vs control bounds (<code>u_min</code>/<code>u_max</code>).</li> <li>[x] Add smoothness cost from <code>diff(action_sequence)</code> and weight <code>w_action_seq_cost</code>.</li> <li>[x] Ensure <code>reset()</code> updates both <code>U</code> and <code>action_sequence</code>.</li> <li>[x] Implement proper shift with action continuity (hold last value).</li> <li>[x] Implement dual bounding system (_bound_control and _bound_action).</li> <li>[x] Recompute effective noise after bounding for accurate cost.</li> </ul>"},{"location":"plan/porting_pytorch_jax/#kmppi-phase-4","title":"KMPPI (Phase 4)","text":"<ul> <li>[x] Implement <code>theta</code> control points + interpolation kernel (RBF by default).</li> <li>[x] Build <code>Tk</code>/<code>Hs</code> grids and re-build on horizon changes.</li> <li>[x] Use <code>solve(Ktktk, K)</code> for interpolation weights (no explicit inverse).</li> <li>[x] Shift <code>theta</code> via interpolation when shifting nominal trajectory.</li> <li>[x] Implement RBFKernel with configurable sigma.</li> <li>[x] Noise sampling in control point space.</li> <li>[x] Batched interpolation with vmap.</li> </ul>"},{"location":"plan/porting_pytorch_jax/#autotune-examples-phase-6","title":"Autotune + Examples (Phase 6)","text":"<ul> <li>[ ] Mirror autotune interface from <code>pytorch_mppi/autotune*.py</code> at a minimal level (evaluation fn + optimizer loop).</li> <li>[ ] Port <code>tests/auto_tune_parameters.py</code> logic into a JAX-friendly example.</li> </ul>"}]}