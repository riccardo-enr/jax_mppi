@inproceedings{Charrow2015-ub,
  title     = {Information-theoretic planning with trajectory optimization for
               dense {3D} mapping},
  author    = {Charrow, Benjamin and Kahn, Gregory and Patil, Sachin and Liu,
               Sikang and Goldberg, Ken and Abbeel, Pieter and Michael, Nathan
               and Kumar, Vijay},
  booktitle = {Robotics: Science and Systems XI},
  publisher = {Robotics: Science and Systems Foundation},
  month     = jul,
  year      = 2015,
  url       = {http://dx.doi.org/10.15607/rss.2015.xi.003},
  doi       = {10.15607/rss.2015.xi.003},
  isbn      = 9780992374716
}

@article{Zhang2020-gi,
  title     = {{FSMI}: Fast computation of Shannon mutual information for
               information-theoretic mapping},
  author    = {Zhang, Zhengdong and Henderson, Theia and Karaman, Sertac and
               Sze, Vivienne},
  journal   = {Int. J. Rob. Res.},
  publisher = {SAGE Publications},
  volume    = 39,
  number    = 9,
  pages     = {1155--1177},
  abstract  = {Exploration tasks are embedded in many robotics applications,
               such as search and rescue and space exploration.
               Information-based exploration algorithms aim to find the most
               informative trajectories by maximizing an information-theoretic
               metric, such as the mutual information between the map and
               potential future measurements. Unfortunately, most existing
               information-based exploration algorithms are plagued by the
               computational difficulty of evaluating the Shannon mutual
               information metric. In this article, we consider the fundamental
               problem of evaluating Shannon mutual information between the map
               and a range measurement. First, we consider 2D environments. We
               propose a novel algorithm, called the fast Shannon mutual
               information (FSMI). The key insight behind the algorithm is that
               a certain integral can be computed analytically, leading to
               substantial computational savings. Second, we consider 3D
               environments, represented by efficient data structures, e.g., an
               OctoMap, such that the measurements are compressed by run-length
               encoding (RLE). We propose a novel algorithm, called FSMI-RLE,
               that efficiently evaluates the Shannon mutual information when
               the measurements are compressed using RLE. For both the FSMI and
               the FSMI-RLE, we also propose variants that make different
               assumptions on the sensor noise distribution for the purpose of
               further computational savings. We evaluate the proposed
               algorithms in extensive experiments. In particular, we show that
               the proposed algorithms outperform existing algorithms that
               compute Shannon mutual information as well as other algorithms
               that compute the Cauchyâ€“Schwarz quadratic mutual information
               (CSQMI). In addition, we demonstrate the computation of Shannon
               mutual information on a 3D map for the first time.},
  month     = aug,
  year      = 2020,
  url       = {http://dx.doi.org/10.1177/0278364920921941},
  doi       = {10.1177/0278364920921941},
  issn      = {0278-3649,1741-3176},
  language  = {en}
}

